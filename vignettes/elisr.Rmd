---
title: "A (more) technical `musclr` companion" 
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{musclr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(musclr)
```

`musclr` is a shortcut for "multiple scaling according to the principle of
crystallization in R". The vignette is a step by step approach to teach, first
and foremost, how to use `musclr`. As the title suggest, this is going happen in
a more technical way. I aim to make you understand what is going on under the
hood. In doing so (i.e., following the examples below), you will further
encounter some benefits of this exploratory procedure which primary lead to the
development of this package. But if one is ought for the full range of
advantages, look at the paper referenced below. There is at least an upcoming
paper which I can't cite right now. But be sure, I will let you know where and
how to find it (as soon as possible). Let's summarize the introduction with the
most important features. After that we dive deeper into the technical details
to make you maximal comfortable when using `musclr`.

#### Most important features 

* The packages offers a multiple scaling approach according to the principle 
  of crystallization for (quasi-)metrical data in R.

* It thus supports you in exploring multidimensional data structures. 

  Note: In common research practice one generally considers explorative factor
  analysis in this case often accepting rigid model assumptions (e.g.,
  orthogonality). 

* `musclr`, or rather its underlying algorithm, tries to bypass such inflexible 
  assumptions in a bottom up manner. 

* As a result the package provides a platform to maximize (a) the identification 
  of relevant dimensions, (b) allowing the scales to naturally correlate with 
  one another to accurately meet the actual conditions. 

 Hint: After exploratorily analyzing the data set with `disjoint()` and 
 `overlap()` you need to further process the result. Additional analysis in 
 mandatory. A solution on how to proceed is mentioned in the last sections. 
 
## `disjoint()` &  `overlap()`

`musclr` basically consists of two user functions `disjoint()` and `overlap()`.
With a typical case in mind, the practical difference between them is:
`disjoint()` is set up to produce sharp and disjoint scale fragments.  Sharp and
disjoint are those fragments, that include items which (a) share a strong linear
relationship with one another but where (b) any of them is tied to a single
fragment. That's where `overlap()` comes into play. Passing fragments to
`overlap()` the functions underlying algorithm tries to enrich each fragment, by
considering the inclusion of every item from your specified data frame but those
in the given fragment. Making a long story short: Using `overlap()` an item can
appear in more than one of the enriched fragments. In doing so, one overcomes
the splitting effect of the data frame induced by `disjoint()`. These basical
principles will unfold throughout the rest of this companion.

Note however, that the paragraph above already reveals the key strategy of any
exploratory analysis using this bottom up item selection procedure: (1) Instruct
`disjoint()` to produce a couple of sharp, disjoint scale fragments from your
specified data frame. (2) Let `overlap()` pick up the pieces; i.e. enrich the
disjoint fragments considering those items that are highly correlating with the
(sum score of the given) fragment. A more detailed explanation goes along with
the following examples.

### Analyzing the trust items using disjoint() and overlap()

`trust` is going to be the data base in the upcoming units. `trust` is a subset
of the German General Social Survey (ALLBUS) 2018 in which participants answered
some questions on their trust in public institutions and organizations. Use
`?trust` for more details. Because the data frame is part of `musclr`, we can
access it easily. 

```{r}
library( musclr ) ; data( trust ) ; head( trust )
```

Let's put things into practice intially. In the first snippet, as I already
said, we will instruct `disjoint()` to produce a couple of sharp fragments. Do
that by setting a relatively high value for the marginal corrected item total
correlation `mrit_min`. To cut things short, I'll use `.55` (mostly because this
value produced satisfactory results in prior analyses -- a more detailed
explanation on how to use this value you will find below).

```{r echo=TRUE}
# `(foo <- baz)`: assign and print in one step
(msdf <-  disjoint(df = trust, mrit_min = .55))
```

#### disjoint()

The table you see in the output below shows an object of type `msdf`. A `msdf`
is nothing more than a named `list` which I extended with a couple of attributes
for internal computational reasons (type`attributes(msdf)`). The printed version
of the modified list is what you should see in the output. If you can't locate
the `msdf`'s components (the fragments are called `$scl_1` and `$scl_2`)
something went wrong. I made `disjoint()` (and `overlap()`) actually complain
about lots of things and set up mostly sensible message for common errors. A
general advice is to watch out for typos. These little goblins are nasty
everyday companions in applied research. But if you can't encrypt the error
message, hack it into google. Done? Alright, then we can go over to the output
section and a get a first indepth impression of `disjoint()`s machinery.

```{r}
msdf
```
First, we should focus on some terminology. Therefore, focus on `$scl_1`. I will
refer to an objects like `scl_1` generally as a fragment. Now look at
(`eupalmnt, eucomisn`). This comma-separated pair of two items in the first
line, is the core of `scl_1`. The core marks the start of the upcoming sclaing
procedure -- a two item scale. As we could see, the core of `$scl_1$ includes
the (lineraly) highest positivly correlating pair chosen from the data frame you
inserted (`trust`). To find it, it sets up a correlation matrix internally and
ask which one is the highest of all. Hint: I there are two equal
correlations`disjoint()` will always chooses the first one in the series. And
that's how the inital of the scaling procedure ends, by finding the highest
correlating pair.

Tech tip: Neither `disjoint()` nor `overlap()` search the highest correlating
pair at any costs. The linear relationship between the core items must be
greater than your pre-set `mrit_min`. I implemented a check for that, so
`disjoint()` will let you know, if it's not it's not the case. Here, everything
went well. Crosscheck that result by looking at the first line:
$mrit=rbar=0.92$. Remember; the pre_specified value for the analysis was
$mrit=.55$.

After `disjoint()` started the two point item scale it tries to fill affiliate
another trust variable. In this case it picked up `polpati`. The algorithmic
background on this sequence is straightforward. First, `disjoint()` starts to
add up both items elementwise. This creates a sumscore. Subsequently, it watches
out for the item with the highest correlation with that sum (`polpati`). Because
the correlation of`polpati` with the added core items is still greater than our
specified stop criterion ($mrit_min=.55$) `polpati` is melted into the core. The
new fragment is now a bundle of 3 Items: `eupalament`, `eucomisn`, and
`polpati.` The same is true for `fedgovt` and reveals the important second step
of the algorithmic procedure: Continue to collect new items from `df` (here:
`trust`), until the correlation between the sum score of the items in the
fragment and any other item is less than your pre-specified `mrit_min.` In that
manner it soaks up the remaing three items you could see in the output -- namely
`bundtag`, `judsyst`, `fccourt`.

Let's now focus on the question, why there is another scale with a `mrit_min`
value greater than the pre-specified one. The reason for this is that the
algorithm tries to build (and enrich) new fragments as long as there are more
remaining variables in your variable list (`df`). More specifially, the
algorithm won't stop to enrich a fragment as long as there is exactly one
variable left (in `trust`). Additionally, it won't interrupt constructing
fragments as long as there are at least two leftovers. But be aware of the fact
that again, `disjoint()` won't necessarily generate (and enrich) new fragments
at any costs. The correlations between items must be positive and greater than
your pre-specified minimum value. That betrays the last unique step of this
disjoint scaling procedure: If there are variables left that meet the
requirements, start another two point item scale.

To sum up, you could test your understanding against the following question: Why
is there no other variable in `$scl_2`? Right, although there are 13 variables
in the data frame, there must have been no other variable among them that meets
the internally defined correlation criteria -- namely, that the sumscore of the
whole fragment is greater than the pre-set $mrit_min$. As a consequence, no
other variable was considered to be merged with `{eupalmnt, eucomisn}`. Double
check in the last line of the given output.

Let's tie in with above in a last step and zoom out on both fragments now. If we
remind ourselves on the description of `disjoint()`s task (to build disjoint
scale fragments), one can derieve from the last couple of steps, that it really
did its job. In the output each variable (`euparlament,...,tv`) is present in
either `$scl_1` or `$scl_2` exactly once. To put it another way, there is no
"intersecting" variable which overlaps in these two fragments. To assure that, I
made `disjoint()` exclude each variable after assign it to a given scale
fragment. In advance of the upcoming sections keep this result in mind.

#### overlap()

Before we'll actually try to enrich the disjoint fragments, we should reprint
the primary output to easily catch up. A one-liner is sufficient for this
purpose. Just type the name of the object you previously stored the results in.
In the prior snippet I called it `msdf`.

```{r}
msdf
# Pint output to n decimal places (default=2)
# print(msdf, digits=2)
```
A little R side note: When calling `msdf` R internally wraps the expression in
`print()`. Thus, `msdf` is a shortcut for `print(msdf)`. But since I wrote a
custom function to print objects of the eponymous type `print()` actually passes
the work on to `print.msdf()`. To get to the point, `print()` owns a nice way to
print the result to a specified number of digits, I equiped `print.msdf()` with
that either. The default is set to 2. Be aware of that omitting tons of decimal
places does not mean that the result is acurately rounded to the specified ones.
Anyway, I decided to avoid any rounding in the results. The reason for that is
R's (as I find, counterintuitive) standard (IEC 60559; see `?round`). So, if you
get into the situation where you need to report more than two decimal places,
expand the result using `digits=n` and choose whatever standard you like.

Let's resume and try to extend the scale with all items, despite those that are
already part of the result. To tie in to above, we're planning to resolve
`disjoint()`'s disjointness now. `overlap()` has the following role; it
(re-)considers the use of each item for a given fragment `disjoint()` has not
(simply because of its disjoint nature). The following two paragraphs will lay
out this ideas in much greater detail. Let's put the results back on the
desktop first.

```{r}
(mosdf <- overlap(msdf, mrit_min = .4))
# Equivalent formalization unmasking the defaults
# (mosdf <- overlap(msdf, mrit_min = .4), overlap_with="fragment" )
```
A quick overview reveals that `overlap()` added a couple of variables to the
basic fragments from `disjoint()`. But what happend inside the machinerie? Well,
first `overlap()` finds all items in the data frame that are not part of the
given fragment. Let's call this its counterpart. Think about the counterpart as
items in the specified data frame minus the items within the fragment.
Accordingly for `$scl_1` the counterpart is made up of the following eight
items: `newsppr`, `tv`, `healserv`, `munadmin`, `tv`, `newsppr`, `uni` and
`police`. The second step is merely a repetition. `overlap()` starts the
previously described scaling procedure in each case over again. It thus
continuesly enriches each fragment with the according items from the counterpart
as long as the correlation between the sum score of all items and any other item
is less than the specified `mrit_min` (reminder:`mrit.min=.4`). To put it
another way, `overlap()` take the disjoint fragments as its basis when trying to
extend any of them. That's why the default option is called
`overlap_with="fragments"`. Additionally, `overlap()` provides the option to
choose only the highest positively correalting pair of each scale fragment
(`overlap_with="core"`). Type `?overlap` for more details. 

To let the key insights sink in, we should rework the whole process in a more
practical example once more. Have a look on the result of the previous functions
call (`mosdf`). What you could see is that there are two fragments `$scl_1`and
`$scl_2`. At second glance they are pretty similar to the result of `msdf`.
Let's take $scl_1$ as an example.

```{r}
lapply( list( msdf=msdf$scl_1, mosdf=mosdf$scl_1 ), colnames )
# lapply( list( msdf=msdf$scl_2, mosdf=mosdf$scl_2 ), colnames )
```

That snippet shows the basis that `msdf` sets up through `disjoint()` for
`mosdf`. Likewise, one could say it demonstrates how `overlap()` extended this
fundament. Anyway, `overlap()` soaked up 6 additionl items from its counterpart
(`police`, ` newsppr`, `tv`, `uni`, `munadmin` & `healserv`). What happend here
algorithmically is, that `overlap()` searched for those items in `trust` that
were missing in `$scl_1`. Then, It used their intersection to build up this
counterpart. Subsequently, `overlap()` checked which correlation of these
variables with the sum score of the basic fragment is the greatest. If that
correlation exceeds the pre-set `mrit_min` it merged that variable into the
fragment. Finally, it starts over again considering the next item if it meets
these conditions. To conclude in more technical terms, those six additional
items tag the additional benefit we get from dissolving "`disjoint()`'s
genuin disjointness". 

There is one curcial step missing with regard to `$scl_2`. When `overlap()`
can't find any further item within a fragment that is worth considering it
continues; in this case `$scl_2`. So finally, what `overlap()` really is (well,
that's how I implemented it), is an enhancement of the disjoint scaling approach
by applying its underlying algorithm stepwise to multiple fragments considering
the according counterpart for their extension. This is what we see looping back
to the result of `overlap()`. There are two scaling fragments where some of the
items are present in both of them. I'll come to that in a moment. Let's clarify
the reason for that first. Even if a particular item is already part of $scl_1$
but nevertheless meets the pre-set admission criterion in `$scl_2`(the sum score
of the fragment and the corresponding item is greater $mrit_{min}=.4$) why not
tagging it as relevant for the developing scale? Note that `overlap()` will.

Now we can unfold the key mechanism when setting `mrit_min`: The more fragments
`disjoint()` produces the more reason one'll give `overlap()` to soak up
appropriate items from the corresponding counterparts. The key insight from
resolving `disjoint()`s disjointness (i.e. using `overlap()`) is that the scales
replicate. Check it against the result or type the follwing lines.

```{r}
lapply( list( scl_1=mosdf$scl_1, scl_2=mosdf$scl_2), 
        function(scl) sort(names(scl)))
```

To sum up, even if we break the list items appart using `disjoint()` we allow
`overlap()` to pick up -- and expand -- its pieces. That is one of the
advantages of this approach. It don't force these fragments to be different.
Although it smashes the induced list of variables, it allows to explore how the
individual parts reuinte. Forcing these scale fragments to be different would
have masked the replication discovery itself. Hence, the breaking and reuiniting
part of this algorithmic procedure (namely the combined use of `disjoint()` and
`overlap()`) are inseparably connected. For this reason, we should consider
their use in a single call.

#### An all in one snippet 

```{r}
msdf <- overlap(
  disjoint( df = trust, mrit_min = .55),
  mrit_min = .4
) 
print(msdf, digits=2)
```

### Further anlysis of the trust items -- including negative correlations

In everyday research, one will usually stumble upon reversed items. These items
are broadly used to diminish response bias and reveal themselves in gerneral
through a negative correlation in the correlation matrix. Since there are no
reversed variables in `trust` we need to make up an artifical one.

```{r}
ntrust <- within( trust, tv <- 8 - tv )
# Compare the results 
# cor(trust, use="pairwise.complete.obs")
# cor(ntrust, use="pairwise.complete.obs")
```

So what this code does, is to subtract $8$ from each value stored in the `uni`
variable, reassign it and store the result in a new data frame called `ntrust`.
From here we could start all over again using the all in one snippet. The only
thing we have to add is to set `negative_too=TRUE`and specify the start and
endpoint of the scale as a two element vector `c(1,7)`.

```{r}
ntrust <- within( trust, uni <- 8 - uni )
```

The first thing we should aim for is to replicate the results from the previous
analysis to understand the machinery and then soften the regularations to become
aware of the gained flexibility. But let's do this in a smoothed pace one step
at the time. To repeat the result from `disjoint()` we need to kind of
"re-reverse" `uni`. `disjoint()` does this for you, if you set the appropriate
options (`negative_too` & `sclvals`). Because we know from the prior results
that `uni` is not part of the fragments, it won't be re-reversed using
`disjoint()`. Usually we don't have this luxury. So setting `negative_too=TRUE`
here, seems like the right thing to do. Oh yes, for that reasons I made both
functions act very coperatively. `disjoint()` and `overlap()` will both let you
know, if they reversed an item (and if so, which one).

```{r}
(d <- disjoint( ntrust, mrit_min=.55, negative_too = TRUE, sclvals = c(1, 7) ))
```
The output is as expected. The result is identical to the one of the prior
analysis (using `trust` and `disjoint()`). We could now simply stick the result
we just stored in `d` into `overlap()`. Note however, that you have to tell
`overlap()`as well, that it should consider to use negative correlations. To
save you some typing, I made `overlap()` remember the start and endpoint of the
scale you've passed to `disjoint()` (see `attributes(d)$sclvals`). So no need to
specify them twice. What we should expect `overlap()` to do next, is to apply
the algortihm to trust therby reverse `uni` internally and second, let you that.

```{r}
overlap(d,
        # Note: overlap() remembers the scaling values from disjoint()
        mrit_min = .4, negative_too=TRUE
)

```
### Another made up (but autodidactic) example

Now its time to play around with the algorithm yourself. In the following snippe
a core item of the second fragment will be reversed. Make predictions of what
will happen and why. Write them down and than and check the result against the
actual output. Done? Well, than remove `#` and see if both match.

```{r}
ntrust <- within( trust, tv <- 8 - tv )

# overlap( 
#  disjoint( ntrust, mrit_min=.55, negative_too = TRUE, sclvals=c(1,7) ),
#        mrit_min = .4, negative_too = TRUE)
```

### Different types of scales

#
#
#
#
#

Let's tie in to 
say stop,here are more scales I came across, what about those? Well, th

There are 3 different types of scales witch `overlap()` can deal with when using
the `negative_too` option.

1. An integer scale starting at 1 (e.g., "1 2 3 4 5 6 7"). Both function use the
formula $(\max sclval + 1) - x$ when setting `scalvals=c(1,7)` in this case.
 
2. An integer scale starting at 0 (e.g., "0 1 2 3 4 5 6 7). The use the formula
$\max sclval - x$. Set `sclvals=c(0,7)`. 

3. An integer scale starting below 0 ( e.g., "-3 -2 -1 0 -1 -2 -3"). The
workhorse here bases simply on the formula `x * (-1)`.

Those 3 option should cover a wide range of application. Despite that, you are
free to use any quasi-metrical scale you like. Just keep in mind the deviations
discussed when manually reversing a set of variables.

NOTE: both function reverse variables if necessary when this option is set
without complaining.

### Dealing with different start- end endpoints of a scale.

A minor issue of `musclr` so far, is that it can't cope with items measured on
scales with different start- and endpoints. However, if you insert those,
`disjoint()` and `overlap()` will silently follow this appeal. They won't
complain. 

There are a couple of ways to deal with this issue in advance. One might
consider the least common multiple for that reason. But be aware that in doing
so you sign off the accordion assumption. That is, one ends up assuming that the
the space between categories grows from stratching in a linear way. That can be
a reasonable assumption sometimes but sometimes it is not. You have to check
such assumptions according to your prior knowledge and the data. Therefore it
would be nonsensical to link this algorithm to and ad-hoc assumptions without
any details of the field and the structure of data at hand.

## Working with the results

In the previous chapters I mentioned the `print.msdf()` function. To make the
output luicd I exploited the fact that R wraps `msdf` internally in `print()`.
When print meets and object of the epynomous type it passes work on to
`print.msdf()` -- which cleary arranges the results.

```{r}
msdf <- overlap( 
        disjoint( ntrust, mrit_min=.55, negative_too = TRUE, sclvals=c(1,7) ),
        # Note: overlap() remembers the scaling values from disjoint()
        mrit_min = .4, negative_too = TRUE 
)

msdf
```

But what happend to the actual output? Well, it is not lost, but hidden by this
internal printing mechanism. But you can break this structure by adressying one
of `msdf`s elements directly. That reveals the raw data list. So, what you
should see in the following output are the first six values of the
algorithmically sorted (and in this case extended) variables of your specified
item list `df=trust`. The sorting itself is done according to your input of the
marginal corrected item total correlations `mrit_min=.55` with `disjoint()` and
`mrit_min=.4` with `overlap()`.

```{r}
head(msdf$scl_1)
```

An additional look at the result reveals that `tv` is still present in reverse.
Aiming to make further analysis as convenient as possible, `disjoint()` and
`overlap()` both keep the reversed form of the variable. If this behaviour is
undesireable, one could easily re-reverse it. Just stick to the previously
discussed formulas. Another convenience is that accessing `msdf` using
`msdf$scl_1` aditionally breaks the breaks the inherent structure of that
object. It is no longer of type `msdf` but a `data.frame` object. That
simplifies getting on with the job.

```{r}
class(msdf$scl_1)
```

## Further anylsis of the results

A final note on what `musclr` leaves you with. Well, what you get from applying
`disjoint()` and `overlap()` is really an intermediate. Let's be clear on this,
the result indicates how the items you've entered are linearly associated with
one another given a reasonable termination criterion. It expands

# Sticking in items you own fragment 


extended sorted version of your data frame with a
decreasing

So postprocessing the
result is mandatory. There are several ways to continue, but the `psych` package
and `sjmisc` by Daniel LÃ¼decke are good places to start. The first on provides
the working horse `alpha()` and the second a comprehensive summary using
`reliab_test()`.



##

Mokken 
 
 
Mokken, R. J., 1971: A Theory and Procedure of Scale
Analysis. With Applications in Political Research. The
Hague/New York: Mouton.
 
 
 
 
Note: devalere the mjmisc (?) package in /Description since otherwise the package
doesnt run on CRAN 



